# 改动记录（ScholarRAG）

> 目的：实时记录本次对话期间，为解决“OpenAlex 召回结果太杂、太旧、不相关”以及“生成阶段偶发空输出”等问题，对仓库做出的代码改动，并附上终端对比证据（改前/改后）。
>
> 范围：`main.py`、`src/retrieval/openalex.py`、`src/graph/expansion.py`、`src/core/llm.py`、`src/core/generator.py`、`src/config.py`。

---

## 1. 需求回顾

- 放弃 `Works().search(query)` 作为主召回方式（BM25F 全文关键词噪音大）。
- 改为：**LLM 将用户自然语言映射为 OpenAlex Concept（Concept ID）** → **用 `Works().filter(...)` 精准召回**。
- 还原 `abstract_inverted_index` 为可读摘要文本作为 RAG 语料。
- 输入保持：`OpenAlexRetriever.search(query, top_k, concept_ids)`；输出为标准化 papers（含 title/year/abstract 等）。

---

## 2. 代码改动概览（按模块）

### 2.1 `src/retrieval/openalex.py`（检索主链路重构）

- **主链路变更**：
  - 从 `Works().search(query)` 改为 `Works().filter(...)` 召回：
    - `has_abstract=True`
    - `from_publication_date=<近N年>`
    - `concepts.id in <Concept IDs>`
- **Concept 映射**：
  - 新增：`_llm_phrases_for_query(query)`：把中文/英文 query 转为英文概念短语（结构化 JSON；失败则回退为“每行一个短语”的纯文本解析）。
  - 新增/增强：`_map_query_to_concept_ids(query, phrases=...)`：用 `Concepts().search(phrase)` 获取候选并输出 Concept IDs。
- **摘要还原**：
  - 增强：`_decode_abstract_inverted_index(...)`：高性能倒排摘要还原（list 预分配 + 填充）。
- **稳定性**：
  - 新增：OpenAlex 请求 `_fetch_with_retries(...)`（指数退避重试），修复 `Response ended prematurely` 这类偶发断流。
  - 改进：当 Concept 映射失败时，不再“全库最新论文”退化；改为 **用 LLM 英文短语做 `Works().search(fallback_phrase)` 的兜底检索**，仍保留近 N 年 + has_abstract，减少噪音。
- **数据清洗**：
  - 新增：过滤明显的未来年份（`publication_year > current_year + 1`）避免 2030/2035 脏数据污染输出。
- **重排**：
  - 使用 `_normalize_terms(phrases)` + `_rank_papers(...)` 对候选进行轻量重排（title/abstract 命中 + 新近度 + 引用量）。
- **成本优化**：
  - 避免同一 query 在 retriever 内部对 LLM 重复调用两次（短语只生成一次并复用）。

### 2.2 `src/graph/expansion.py`（图扩展更稳）

- **目的**：解决 `--use_graph` 下经常出现 `No matching concept found in KG.` 的问题（尤其是问句/长句、中文）。
- **增强点**：
  - LLM JSON 失败时回退：纯文本“每行一个短语”解析，避免中文 query 直接进 `Concepts().search()` 失败。
  - 对 `Concepts().search()` 增加 3 次指数退避重试，降低偶发网络/服务端波动导致的空结果。
  - 保持输出结构：仍返回 `{id, name, level}`。

### 2.3 `src/core/llm.py`（OpenRouter 支持 + 空输出诊断）

- **OpenRouter**：支持通过 `OPENROUTER_API_KEY` 与 `OPENROUTER_BASE_URL` 走 OpenAI-compatible 接口。
- **结构化输出**：新增 `chat_json()` + JSON 提取器，提升概念映射稳定性。
- **空输出问题修复**：当 provider 返回 `choices[0].message.content` 为空时，返回可诊断错误字符串（含 `model/finish_reason/tool_calls`），不再静默返回空串。

### 2.4 `src/core/generator.py`（生成兜底）

- 如果 `llm.chat(...)` 返回空字符串，返回明确提示：`LLM 返回空内容...`，避免用户看到“空白综述”。

### 2.5 `main.py`（CLI 参数与 Key 校验）

- Key 校验：允许 `OPENAI_API_KEY` **或** `OPENROUTER_API_KEY` 任一存在即可运行。
- `--top_k`：允许自定义 TopK（默认走 settings / `.env`）。

### 2.6 `src/config.py`

- 增加 OpenRouter 配置项（不强依赖 `OPENAI_API_KEY`）。
- `RAG_TOP_K` 默认值由用户本地选择（对话期间曾调整；以你当前仓库为准）。

---

## 3. 终端证据（改前 vs 改后）

> 说明：以下片段来自你的终端文件 `terminals/2.txt`（已读取并摘录关键行）。

### 3.1 “生成阶段空输出” → “可诊断错误信息”

**改前现象**：生成阶段无报错但输出为空白综述（只看到分隔线）。

**改后证据**（已出现可诊断错误字符串）：

```340:391:terminals/2.txt
16:38:55 | INFO | Sending to LLM...

#################### RESEARCH REVIEW ####################

############################################################
...
17:02:51 | ERROR | LLM Call Failed: empty content (model=openai/gpt-5-nano, finish_reason=length, tool_calls=no)

#################### RESEARCH REVIEW ####################
LLM Call Failed: empty content (model=openai/gpt-5-nano, finish_reason=length, tool_calls=no)
############################################################
```

### 3.2 中文 query（Concept 映射失败）导致“全库噪音” → 改为 “英文短语兜底 search” 后结果显著改善

**改前（差的结果）**：Concept 映射失败 → 退化到“全库最新论文”，出现明显不相关且包含未来年份：

```392:419:terminals/2.txt
17:05:31 | WARNING | No matching concept found in KG.
17:05:48 | WARNING | No concept IDs mapped; will fallback to looser retrieval.
...
Retrieved 5 Papers:
- [2030] Entrepreneurship and regional development: the role of clusters (Cited: 15)
- [2030] Quality management practice: universal or context dependent? ...
- [2035] Consciousness, Self-Consciousness, and the Nested Vacuum Structure: ...
```

**改后（改善结果）**：Concept 仍可能失败，但会兜底为 `Works.search(英文短语)`，结果明显更接近“蛋白质预测/结构”相关：

```420:447:terminals/2.txt
17:13:14 | WARNING | No matching concept found in KG.
17:13:27 | WARNING | No concept IDs mapped; will fallback to looser retrieval.
17:13:27 | WARNING | No concept IDs mapped; fallback to Works.search with phrase='Machine learning-based protein structure prediction'
...
Retrieved 5 Papers:
- [2025] A Comparative Study of Deep Learning and Classical Modeling Approaches for Protein–Ligand Binding Pose and Affinity Prediction ...
...
#################### RESEARCH REVIEW ####################
以下是一份基于你提供的论文清单所撰写的“如何用机器学习做蛋白质预测”的综合文献综述。...
```

---

## 4. 当前已知待优化点（后续可选）

- **ConceptExpander 仍可能在中文 query 上返回 None**：虽然已加入短语回退与重试，但 Concepts 命中率仍受模型输出质量影响；如需更稳可引入“先翻译/关键词抽取→Concepts.search 多轮候选→LLM 决策”。
- **`openai/gpt-5-nano` finish_reason=length**：需要调小输入 context 或增大 max_tokens / 换更大上下文模型，否则可能继续出现截断。



## a successful example
#################### RESEARCH REVIEW ####################
以下文献综述基于你提供的五篇论文，聚焦“RAG是什么及其应用与局限”，并按主题对研究进行归类、综合分析与批判性评价。

一、对 RAG 的定义与研究脉络（基于所提供论文的共识与差异）
- RAG（Retrieval-Augmented Generation，检索增强生成）在这组研究中指通过将外部知识检索纳入生成过程，帮助模型在生成时获得更多、更新或更结构化的信息，以提高任务表现、可解释性或一致性。不同论文在“何时检索、如何检索、检索哪些源、以及如何将检索结果融入生成”上有不同侧重与实现细节。
- 具体表现为：静态检索与动态检索并行演进；将检索结果组织成结构化数据、证据链或可解释的组块；以及通过对检索源和知识结构的管控来应对生成过程中的幻觉与错误信息问题（尽管后文对这一点有更深入的讨论）[Paper 1]、[Paper 2]、[Paper 3]、[Paper 4]、[Paper 5]。

二、主题性综述与关键发现

1) RAG 提升任务的一致性与稳定性（以外部数据帮助评估/对齐为主）
- 关键发现：在 ESG 评分任务中，通过 RAG 过程，三种大语言模型（Claude-4、ChatGPT-4o、Gemini-2.5）对九家公司环境、社会、治理评分的稳定性提升，并与现有机构评级（Morningstar Sustainalytics、S&P Global、JUST Capital）的结果更一致。这表明 RAG 有助于将生成过程与外部结构化标准对齐，从而提升评分的一致性与可靠性[Paper 1]。
- 含义与局限：该研究集中在“评分一致性”这一高层目标，显示 RAG 在把结构化标准落地到具体评估任务中的潜力。但其适用性、可迁移性以及在其他领域的稳定性仍需更多跨领域案例验证。

2) 动态检索、不确定性量化与对抗幻觉的范式（将“何时检索”和“如何验证检索到的信息”放在核心）
- 关键发现：QuCo-RAG 提出基于预训练语料的客观统计来量化不确定性，而非仅依赖模型内部信号（如 logits、熵等）。其两阶段策略包括：在生成前识别低频实体以发现知识空缺；生成过程中验证实体在预训练语料中的共现性，零共现通常表明幻觉风险。通过毫秒级查询的 Infini-gram，触发高风险情景下的检索。实验显示对多跳问答基准的 EM 提升（5–12 点，甚至在未披露预训练数据的模型上仍有显著收益），并具备领域泛化能力（包括生物医学领域）。该研究强调“基于语料的证据-核验”是一个模型无关的、原则性的动态 RAG 框架[Paper 2]。
- 含义与局限：该工作把焦点从单纯的检索—生成循环，提升到“基于大规模语料的证据核验”与“降低幻觉”的范式转变，有效性体现在跨模型与跨域。局限在于仍然依赖大规模预训练语料的覆盖性与统计共现关系，且对极端噪声或罕见事实的处理仍需更多评估。

3) RAG 与符号回归/知识整合的增能框架（将检索用于知识累积与可解释性提升）
- 关键发现：SR-LLM 将 Retrieval-Augmented Generation 应用于符号回归任务，通过 LLM-驱动的检索整合先前知识，将信息拆分为小的符号组并通过深度强化学习组合，形成可解释且更具泛化能力的解析表达式。该框架不仅在标准符号回归基准上表现优于对比方法，还能把从观测轨迹中得到的领域知识用于描述复杂人类驾驶行为的模型，重新发现经典模型并发现新模型，强调“在前人经验的基础上往往能更高效地探索解空间并提升可解释性”[Paper 3]。
- 含义与局限：这一工作扩展了 RAG 的应用场景，显示其在需要将外部知识、历史探索结果系统化、并以可解释表达式形式呈现的任务中的潜力。局限在于符号回归领域的适用性可能对数据与领域依赖较强，且如何普适地衡量解释性与可重复性仍需更多研究。

4) 源约束并非幻觉的万金油：RAG 并不能根本解决幻觉问题（源-grounding 的局限性）
- 关键发现：两项关于 Google NotebookLM 的对照与再现实验表明，即便存在源-grounding（限制输出只基于已上传文档等来源），RAG 仍会出现幻觉；幻觉更多源自语义权威性缺失（semantic authority）的不足，而不是简单的知识来源不足。这意味着检索为系统带来来源约束，但并不能自动解决意义理解、解释与多义性竞合所引发的幻觉问题。论文明确指出“来源约束并不引入语义治理原语”，幻觉在严格的语义支配/冲突情境下仍可能出现，且需要更高层次的语义治理框架来实现真正的可控性和可靠性[Paper 4]、[Paper 5]。
- 含义与局限：这一组研究提供了对 RAG 的重要警示——获取知识来源并进行检索并不足以解决生成质量与一致性问题。真正的挑战在于“语义权威性与治理结构（semantic governance）”的建立，这超出了简单的检索和源约束的能力范围。

三、趋势、共性与矛盾点（对比与综合）

- 共性趋势
  - 外部知识源的引入可以提升特定任务的表现，如一致性、可解释性、以及跨模态任务的泛化能力（如跨领域、跨任务的鲁棒性）[Paper 1]、[Paper 2]、[Paper 3]。
  - 动态、证据驱动的检索策略成为提升鲁棒性的重要路径，尤其在高风险、长尾知识、以及多步推理任务中显示出明显优势[Paper 2]。
  - 将检索结果以结构化、可追溯的形式组织，便于对输出做最近似证据的追踪与解释，提升任务的可解释性和可审计性[Paper 1]、[Paper 3]。

- 矛盾点与挑战
  - 幻觉问题并未因引入 RAG 而根本解决，尤其是当知识来源被严格限定时，仍可能出现一致性不足、语义歧义导致的错误输出。源-grounding 并非语义治理的替代品，需提升“语义治理（semantic governance）”原语和机制来真正减少幻觉[Paper 4]、[Paper 5]。
  - 证据性与可解释性之间的平衡仍需优化：在符号回归等高度可解释化的任务中，尽管 SR-LLM 能生成更易理解的表达，但其可靠性、对新领域的适应性及对复杂推理的鲁棒性仍需在多领域继续验证[Paper 3]。

四、方法学的共性与局限（对研究设计的反思）
- 公共特征：五篇论文都以“LLM + 检索”为核心设计，强调外部知识的引入、证据驱动的输出、以及对输出可靠性的关注。评估指标多围绕一致性、精确性（EM/正确性）、以及对抗幻觉的能力展开（尤其是 Paper 2 的 EM 增益与域泛化测试）。
- 局限性：在提供的研究中，绝大多数工作仍以实验性基准为主，缺乏对长期部署环境（真实系统中的持续知识更新、版本控制与治理机制）的全面评估。此外，跨领域适用性仍需更多、更加多样化的数据集和任务来支撑。

五、对“RAG是什么”的综合回答（基于当前文献的结论性表述）
- RAG 是一种通过在生成过程中引入外部知识检索来增强模型输出的框架。它可以通过以下方式实现价值：
  - 提高任务输出的一致性与对齐性（如 ESG 评分与现有评级的一致性提升）[Paper 1]。
  - 通过动态、不确定性驱动的检索策略降低幻觉风险，并强化对证据的核验与证据级推理能力（尤其在多跳问答等需要长尾知识的任务中）[Paper 2]。
  - 将外部知识或历史探索结果系统化，作为符号化、可解释的推理组块来构造复杂表达式（符号回归例）[Paper 3]。
  - 需要警惕其局限性：即使有源约束，RAG 也不能从根本上消除幻觉；缺乏有效的语义治理原语可能导致严重的误导输出，依赖单纯的检索与证据约束不足以实现真正的可控性与可靠性[Paper 4]、[Paper 5]。

六、对未来研究的建议（基于论文中的启示与不足）
- 强化语义治理与权威性管理：在 RAG 框架中不仅要控制信息来源，还要建立“语义权威性”的治理原语，以解决多义性、歧义性与推理冲突，减少幻觉的根源性驱动[Paper 4]、[Paper 5]。
- 更丰富的领域与任务评估：将 RAG 的应用扩展到更多领域（如生物医学、自动驾驶、社会治理等）并在真实系统环境中评估长期稳定性与可维护性[Paper 2]。
- 融合解释性与证据链追踪：发展将检索结果以可追溯、可验证的证据链形式呈现的机制，进一步提升输出的可解释性与合规性（对外部审计友好）。
- 结合符号化推理与深度学习的混合方法：如 SR-LLM 的思路，进一步探索如何在复杂推理任务中实现高效的知识重用、可解释性与泛化性之间的权衡[Paper 3]。

结论
就目前提供的五篇论文来看，RAG 作为一种“检索增强的生成框架”在提升一致性、降低幻觉风险、以及支持复杂推理与可解释表达方面展现出显著潜力（尤其在 ESG 评分、动态证据核验与符号化推理任务中）。然而，幻觉的根源并非单纯来自知识的缺失，而是涉及语义权威性、推理冲突与多源信息整合的治理问题。因此，未来的研究需要在提升检索质量与证据可验证性的同时，建立更强的语义治理原语，才能让 RAG 在实际应用中更加可靠、可控并具备长期部署的可持续性。



## 5. 通俗版技术总结（一段话）

本次改动把 ScholarRAG 的“检索”从 OpenAlex 的 `Works.search`（BM25F 关键词全文检索，容易把老高引/同词异义的噪音搜出来）切换为“LLM 先把用户问题翻译/抽象成英文概念短语 → 用 `Concepts.search` 找到真实的 Concept ID → 用 `Works.filter`（近 10 年 + has_abstract + concepts.id）做精准召回”，并补上 `abstract_inverted_index` 的高性能还原作为 RAG 语料；同时为 OpenAlex/Concepts 请求加入 3 次指数退避重试以对抗断流与抖动，并在 Concept 映射失败时用英文短语做 `Works.search` 作为兜底避免退化成“全库最新论文”；生成侧增加 OpenRouter 支持与“空 content”诊断/兜底提示，外加未来年份脏数据过滤与减少重复 LLM 调用，从而让召回更相关、更稳定，也更容易排查问题。